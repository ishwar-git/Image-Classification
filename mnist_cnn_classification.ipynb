{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be694738",
   "metadata": {},
   "source": [
    "# üß† Interactive CNN Image Classification on MNIST (PyTorch)\n",
    "\n",
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ishwar-git/Image-Classification/blob/main/mnist_cnn_classification.ipynb)\n",
    "\n",
    "\n",
    "## Objective\n",
    "Aim of this notebook is to use a **CNN** on MNIST to understand image classification ‚Äî with visuals, analysis, training, evaluation, error analysis, and intuition.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ccb1b87",
   "metadata": {},
   "source": [
    "## üì¶ Step 0: Import Libraries & Set Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b7774a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Optional: tqdm progress bar\n",
    "try:\n",
    "    from tqdm.auto import tqdm\n",
    "    TQDM = True\n",
    "except:\n",
    "    TQDM = False\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6e0e21",
   "metadata": {},
   "source": [
    "> ‚ùì **Mini Quiz**: Why we do Normalization ? \n",
    "> üìù Try to answer first: It centers and scales the input so training becomes stable and converges faster."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b7d314",
   "metadata": {},
   "source": [
    "## üìä Step 1: Download, Load & Analyze MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44da6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform: Tensor + Normalize (MNIST mean=0.1307, std=0.3081)\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset  = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "print('Total Training Samples:', len(train_dataset))\n",
    "print('Total Test Samples:', len(test_dataset))\n",
    "print('Classes:', train_dataset.classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337c88d5",
   "metadata": {},
   "source": [
    "## üñº Step 2: Visualize Sample Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff555408",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 6, figsize=(10,3))\n",
    "for i in range(6):\n",
    "    img, label = train_dataset[i]\n",
    "    axes[i].imshow(img.squeeze(), cmap='gray')\n",
    "    axes[i].set_title(f'Label: {label}')\n",
    "    axes[i].axis('off')\n",
    "plt.suptitle('Sample MNIST Images')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef15a055",
   "metadata": {},
   "source": [
    "## üìä Step 3: Class-wise Distribution (Train Split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47957d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels, counts = np.unique(train_dataset.targets.numpy(), return_counts=True)\n",
    "plt.figure(figsize=(8,3.5))\n",
    "plt.bar(labels, counts)\n",
    "plt.title('Number of Images per Digit (Train)')\n",
    "plt.xlabel('Digit Class')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f651ca",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Step 4: Data Augmentation & DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a13cb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple augmentation for training (slight rotation); test set no augmentation\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomRotation(degrees=10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "# Re-create datasets with augmentation for train\n",
    "train_dataset_aug = datasets.MNIST(root='./data', train=True, download=True, transform=train_transform)\n",
    "\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset_aug, batch_size=batch_size, shuffle=True)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print('Training batches:', len(train_loader))\n",
    "print('Testing batches:', len(test_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9b4870",
   "metadata": {},
   "source": [
    "## üèó Step 5: Build a Simple CNN Model (PyTorch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2775a2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.pool  = nn.MaxPool2d(2,2)\n",
    "        self.fc1   = nn.Linear(64*7*7, 128)\n",
    "        self.fc2   = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))          # 1x28x28 -> 32x28x28\n",
    "        x = self.pool(F.relu(self.conv2(x)))# 32x28x28 -> 64x28x28 -> pool -> 64x14x14\n",
    "        x = torch.flatten(x, 1)            # -> 64*14*14 = 12544 (but padding+pool -> 64*14*14); \n",
    "                                           # our layer uses 64*7*7 b/c two pools expected; we used one pool.\n",
    "                                           # Adjust: add another pool to match 64*7*7\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2898b16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.pool  = nn.MaxPool2d(2,2)\n",
    "        self.fc1   = nn.Linear(64*7*7, 128) # after two pools on 28 -> 14 -> 7\n",
    "        self.fc2   = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))          # 1x28x28 -> 32x28x28\n",
    "        x = self.pool(F.relu(self.conv2(x)))# -> 64x14x14\n",
    "        x = self.pool(x)                    # -> 64x7x7\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "model = SimpleCNN().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c684eb60",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Step 6: Loss Function & Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7407619",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a4528c",
   "metadata": {},
   "source": [
    "## üèãÔ∏è Step 7: Training & Testing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f594a76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, loader, optimizer, loss_fn, device):\n",
    "    model.train()\n",
    "    running = 0.0\n",
    "    it = loader\n",
    "    if TQDM:\n",
    "        it = tqdm(loader, leave=False)\n",
    "    for data, target in it:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        loss = loss_fn(out, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running += loss.item()\n",
    "    return running/len(loader)\n",
    "\n",
    "def evaluate(model, loader, loss_fn, device):\n",
    "    model.eval()\n",
    "    running = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            out = model(data)\n",
    "            loss = loss_fn(out, target)\n",
    "            running += loss.item()\n",
    "            pred = out.argmax(dim=1)\n",
    "            correct += (pred == target).sum().item()\n",
    "            total += target.size(0)\n",
    "    return running/len(loader), 100.0*correct/total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4ff26f",
   "metadata": {},
   "source": [
    "## üìà Step 8: Train the Model & Track Progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ab4053",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "test_accuracies = []\n",
    "\n",
    "for epoch in range(1, epochs+1):\n",
    "    tr_loss = train_one_epoch(model, train_loader, optimizer, loss_fn, device)\n",
    "    te_loss, te_acc = evaluate(model, test_loader, loss_fn, device)\n",
    "    train_losses.append(tr_loss)\n",
    "    test_losses.append(te_loss)\n",
    "    test_accuracies.append(te_acc)\n",
    "    print(f'Epoch {epoch}/{epochs} - Train Loss: {tr_loss:.4f} | Test Loss: {te_loss:.4f} | Test Acc: {te_acc:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353f0f82",
   "metadata": {},
   "source": [
    "## üìä Step 9: Plot Training Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a1f3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(test_losses, label='Test Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss Curves')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(test_accuracies, label='Test Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Accuracy Curve')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98582440",
   "metadata": {},
   "source": [
    "## üîç Step 10: Sample Predictions (Correct & Wrong)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10491dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "data_iter = iter(test_loader)\n",
    "images, labels = next(data_iter)\n",
    "with torch.no_grad():\n",
    "    outputs = model(images.to(device))\n",
    "preds = outputs.argmax(dim=1).cpu()\n",
    "\n",
    "fig, axes = plt.subplots(2, 5, figsize=(10,4))\n",
    "axes = axes.flatten()\n",
    "for i, ax in enumerate(axes):\n",
    "    ax.imshow(images[i][0], cmap='gray')\n",
    "    ax.set_title(f'Pred: {preds[i].item()} | True: {labels[i].item()}')\n",
    "    ax.axis('off')\n",
    "plt.suptitle('Sample Predictions')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b368abab",
   "metadata": {},
   "source": [
    "## üìâ Step 11: Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce073ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "all_preds = []\n",
    "all_targets = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "        out = model(data.to(device))\n",
    "        p = out.argmax(dim=1).cpu().numpy()\n",
    "        all_preds.extend(p)\n",
    "        all_targets.extend(target.numpy())\n",
    "\n",
    "cm = confusion_matrix(all_targets, all_preds)\n",
    "\n",
    "# Plot using matplotlib to avoid dependency on seaborn\n",
    "fig, ax = plt.subplots(figsize=(6,5))\n",
    "im = ax.imshow(cm, interpolation='nearest')\n",
    "ax.figure.colorbar(im, ax=ax)\n",
    "ax.set(xticks=np.arange(10), yticks=np.arange(10), xlabel='Predicted', ylabel='True', title='Confusion Matrix')\n",
    "for i in range(10):\n",
    "    for j in range(10):\n",
    "        ax.text(j, i, cm[i, j], ha='center', va='center', fontsize=8)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efdad96e",
   "metadata": {},
   "source": [
    "## üß† Step 12: Visualize Feature Maps (What CNN Sees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1675750",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "image, label = test_dataset[0]\n",
    "image = image.unsqueeze(0).to(device)\n",
    "with torch.no_grad():\n",
    "    fmap1 = model.conv1(image).cpu()\n",
    "\n",
    "fig, axes = plt.subplots(4, 8, figsize=(10,5))\n",
    "axes = axes.flatten()\n",
    "for i, ax in enumerate(axes):\n",
    "    if i < fmap1.shape[1]:\n",
    "        ax.imshow(fmap1[0, i], cmap='gray')\n",
    "    ax.axis('off')\n",
    "plt.suptitle('Feature Maps after conv1')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2541c34",
   "metadata": {},
   "source": [
    "## üéì Step 13: Student Experiment Zone\n",
    "Try these:\n",
    "- Add **Dropout** between layers\n",
    "- Change **learning rate**\n",
    "- Increase **filters** (e.g., 32‚Üí64, 64‚Üí128)\n",
    "- Add **BatchNorm** after conv layers\n",
    "- Train for **more epochs** and compare curves\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4afec4d7",
   "metadata": {},
   "source": [
    "## üíæ Step 14: Save & Load the Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d41acb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save\n",
    "torch.save(model.state_dict(), 'mnist_cnn_model.pth')\n",
    "print('Model saved as mnist_cnn_model.pth')\n",
    "\n",
    "# Load\n",
    "loaded = SimpleCNN().to(device)\n",
    "loaded.load_state_dict(torch.load('mnist_cnn_model.pth', map_location=device))\n",
    "loaded.eval()\n",
    "print('Model loaded back!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090c82d5",
   "metadata": {},
   "source": [
    "## ‚úÖ Conclusion & Next Steps\n",
    "**You learned:** data prep, CNN basics, training, evaluation, confusion matrix, and feature visualization.  \n",
    "**Next:** Try deeper CNNs (VGG/ResNet), switch to CIFAR-10, and play with augmentation/regularization.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
