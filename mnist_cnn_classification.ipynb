{"cells": [{"cell_type": "markdown", "metadata": {}, "source": "# \ud83e\udde0 Interactive CNN Image Classification on MNIST (PyTorch)\n\n[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/USERNAME/REPO_NAME/blob/main/mnist_cnn_interactive.ipynb)\n\n## \ud83c\udfaf Objective\nIs notebook ka aim hai students ko **CNN** ka use karke MNIST par image classification sikh\u093e\u0928\u093e \u2014 with visuals, analysis, training, evaluation, error analysis, and intuition.\n\n---\n"}, {"cell_type": "markdown", "metadata": {}, "source": "## \ud83d\udce6 Step 0: Import Libraries & Set Device"}, {"cell_type": "code", "metadata": {}, "source": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import DataLoader\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Optional: tqdm progress bar\ntry:\n    from tqdm.auto import tqdm\n    TQDM = True\nexcept:\n    TQDM = False\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint('Using device:', device)", "outputs": [], "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": "> \u2753 **Mini Quiz**: Normalization \u0915\u094d\u092f\u094b\u0902 \u0915\u0930\u0924\u0947 \u0939\u0948\u0902?  \n> \ud83d\udcdd Try to answer first: It centers and scales the input so training becomes stable and converges faster."}, {"cell_type": "markdown", "metadata": {}, "source": "## \ud83d\udcca Step 1: Download, Load & Analyze MNIST"}, {"cell_type": "code", "metadata": {}, "source": "# Transform: Tensor + Normalize (MNIST mean=0.1307, std=0.3081)\ntransform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize((0.1307,), (0.3081,))\n])\n\ntrain_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\ntest_dataset  = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n\nprint('Total Training Samples:', len(train_dataset))\nprint('Total Test Samples:', len(test_dataset))\nprint('Classes:', train_dataset.classes)", "outputs": [], "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": "## \ud83d\uddbc Step 2: Visualize Sample Images"}, {"cell_type": "code", "metadata": {}, "source": "fig, axes = plt.subplots(1, 6, figsize=(10,3))\nfor i in range(6):\n    img, label = train_dataset[i]\n    axes[i].imshow(img.squeeze(), cmap='gray')\n    axes[i].set_title(f'Label: {label}')\n    axes[i].axis('off')\nplt.suptitle('Sample MNIST Images')\nplt.show()", "outputs": [], "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": "## \ud83d\udcca Step 3: Class-wise Distribution (Train Split)"}, {"cell_type": "code", "metadata": {}, "source": "labels, counts = np.unique(train_dataset.targets.numpy(), return_counts=True)\nplt.figure(figsize=(8,3.5))\nplt.bar(labels, counts)\nplt.title('Number of Images per Digit (Train)')\nplt.xlabel('Digit Class')\nplt.ylabel('Count')\nplt.show()", "outputs": [], "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": "## \u2699\ufe0f Step 4: Data Augmentation & DataLoaders"}, {"cell_type": "code", "metadata": {}, "source": "# Simple augmentation for training (slight rotation); test set no augmentation\ntrain_transform = transforms.Compose([\n    transforms.RandomRotation(degrees=10),\n    transforms.ToTensor(),\n    transforms.Normalize((0.1307,), (0.3081,))\n])\n\n# Re-create datasets with augmentation for train\ntrain_dataset_aug = datasets.MNIST(root='./data', train=True, download=True, transform=train_transform)\n\nbatch_size = 64\ntrain_loader = DataLoader(train_dataset_aug, batch_size=batch_size, shuffle=True)\ntest_loader  = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n\nprint('Training batches:', len(train_loader))\nprint('Testing batches:', len(test_loader))", "outputs": [], "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": "## \ud83c\udfd7 Step 5: Build a Simple CNN Model (PyTorch)"}, {"cell_type": "code", "metadata": {}, "source": "class SimpleCNN(nn.Module):\n    def __init__(self):\n        super(SimpleCNN, self).__init__()\n        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n        self.pool  = nn.MaxPool2d(2,2)\n        self.fc1   = nn.Linear(64*7*7, 128)\n        self.fc2   = nn.Linear(128, 10)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))          # 1x28x28 -> 32x28x28\n        x = self.pool(F.relu(self.conv2(x)))# 32x28x28 -> 64x28x28 -> pool -> 64x14x14\n        x = torch.flatten(x, 1)            # -> 64*14*14 = 12544 (but padding+pool -> 64*14*14); \n                                           # our layer uses 64*7*7 b/c two pools expected; we used one pool.\n                                           # Adjust: add another pool to match 64*7*7\n        return x", "outputs": [], "execution_count": null}, {"cell_type": "code", "metadata": {}, "source": "class SimpleCNN(nn.Module):\n    def __init__(self):\n        super(SimpleCNN, self).__init__()\n        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n        self.pool  = nn.MaxPool2d(2,2)\n        self.fc1   = nn.Linear(64*7*7, 128) # after two pools on 28 -> 14 -> 7\n        self.fc2   = nn.Linear(128, 10)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))          # 1x28x28 -> 32x28x28\n        x = self.pool(F.relu(self.conv2(x)))# -> 64x14x14\n        x = self.pool(x)                    # -> 64x7x7\n        x = torch.flatten(x, 1)\n        x = F.relu(self.fc1(x))\n        x = self.fc2(x)\n        return x\n\nmodel = SimpleCNN().to(device)\nprint(model)", "outputs": [], "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": "## \u2699\ufe0f Step 6: Loss Function & Optimizer"}, {"cell_type": "code", "metadata": {}, "source": "loss_fn = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=1e-3)", "outputs": [], "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": "## \ud83c\udfcb\ufe0f Step 7: Training & Testing Functions"}, {"cell_type": "code", "metadata": {}, "source": "def train_one_epoch(model, loader, optimizer, loss_fn, device):\n    model.train()\n    running = 0.0\n    it = loader\n    if TQDM:\n        it = tqdm(loader, leave=False)\n    for data, target in it:\n        data, target = data.to(device), target.to(device)\n        optimizer.zero_grad()\n        out = model(data)\n        loss = loss_fn(out, target)\n        loss.backward()\n        optimizer.step()\n        running += loss.item()\n    return running/len(loader)\n\ndef evaluate(model, loader, loss_fn, device):\n    model.eval()\n    running = 0.0\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for data, target in loader:\n            data, target = data.to(device), target.to(device)\n            out = model(data)\n            loss = loss_fn(out, target)\n            running += loss.item()\n            pred = out.argmax(dim=1)\n            correct += (pred == target).sum().item()\n            total += target.size(0)\n    return running/len(loader), 100.0*correct/total", "outputs": [], "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": "## \ud83d\udcc8 Step 8: Train the Model & Track Progress"}, {"cell_type": "code", "metadata": {}, "source": "epochs = 5\ntrain_losses = []\ntest_losses = []\ntest_accuracies = []\n\nfor epoch in range(1, epochs+1):\n    tr_loss = train_one_epoch(model, train_loader, optimizer, loss_fn, device)\n    te_loss, te_acc = evaluate(model, test_loader, loss_fn, device)\n    train_losses.append(tr_loss)\n    test_losses.append(te_loss)\n    test_accuracies.append(te_acc)\n    print(f'Epoch {epoch}/{epochs} - Train Loss: {tr_loss:.4f} | Test Loss: {te_loss:.4f} | Test Acc: {te_acc:.2f}%')", "outputs": [], "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": "## \ud83d\udcca Step 9: Plot Training Curves"}, {"cell_type": "code", "metadata": {}, "source": "plt.figure(figsize=(10,4))\nplt.plot(train_losses, label='Train Loss')\nplt.plot(test_losses, label='Test Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.title('Loss Curves')\nplt.legend()\nplt.show()\n\nplt.figure(figsize=(10,4))\nplt.plot(test_accuracies, label='Test Accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy (%)')\nplt.title('Accuracy Curve')\nplt.legend()\nplt.show()", "outputs": [], "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": "## \ud83d\udd0d Step 10: Sample Predictions (Correct & Wrong)"}, {"cell_type": "code", "metadata": {}, "source": "model.eval()\ndata_iter = iter(test_loader)\nimages, labels = next(data_iter)\nwith torch.no_grad():\n    outputs = model(images.to(device))\npreds = outputs.argmax(dim=1).cpu()\n\nfig, axes = plt.subplots(2, 5, figsize=(10,4))\naxes = axes.flatten()\nfor i, ax in enumerate(axes):\n    ax.imshow(images[i][0], cmap='gray')\n    ax.set_title(f'Pred: {preds[i].item()} | True: {labels[i].item()}')\n    ax.axis('off')\nplt.suptitle('Sample Predictions')\nplt.show()", "outputs": [], "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": "## \ud83d\udcc9 Step 11: Confusion Matrix"}, {"cell_type": "code", "metadata": {}, "source": "from sklearn.metrics import confusion_matrix\n\nall_preds = []\nall_targets = []\nmodel.eval()\nwith torch.no_grad():\n    for data, target in test_loader:\n        out = model(data.to(device))\n        p = out.argmax(dim=1).cpu().numpy()\n        all_preds.extend(p)\n        all_targets.extend(target.numpy())\n\ncm = confusion_matrix(all_targets, all_preds)\n\n# Plot using matplotlib to avoid dependency on seaborn\nfig, ax = plt.subplots(figsize=(6,5))\nim = ax.imshow(cm, interpolation='nearest')\nax.figure.colorbar(im, ax=ax)\nax.set(xticks=np.arange(10), yticks=np.arange(10), xlabel='Predicted', ylabel='True', title='Confusion Matrix')\nfor i in range(10):\n    for j in range(10):\n        ax.text(j, i, cm[i, j], ha='center', va='center', fontsize=8)\nplt.tight_layout()\nplt.show()", "outputs": [], "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": "## \ud83e\udde0 Step 12: Visualize Feature Maps (What CNN Sees)"}, {"cell_type": "code", "metadata": {}, "source": "model.eval()\nimage, label = test_dataset[0]\nimage = image.unsqueeze(0).to(device)\nwith torch.no_grad():\n    fmap1 = model.conv1(image).cpu()\n\nfig, axes = plt.subplots(4, 8, figsize=(10,5))\naxes = axes.flatten()\nfor i, ax in enumerate(axes):\n    if i < fmap1.shape[1]:\n        ax.imshow(fmap1[0, i], cmap='gray')\n    ax.axis('off')\nplt.suptitle('Feature Maps after conv1')\nplt.show()", "outputs": [], "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": "## \ud83c\udf93 Step 13: Student Experiment Zone\nTry these:\n- Add **Dropout** between layers\n- Change **learning rate**\n- Increase **filters** (e.g., 32\u219264, 64\u2192128)\n- Add **BatchNorm** after conv layers\n- Train for **more epochs** and compare curves\n"}, {"cell_type": "markdown", "metadata": {}, "source": "## \ud83d\udcbe Step 14: Save & Load the Trained Model"}, {"cell_type": "code", "metadata": {}, "source": "# Save\ntorch.save(model.state_dict(), 'mnist_cnn_model.pth')\nprint('Model saved as mnist_cnn_model.pth')\n\n# Load\nloaded = SimpleCNN().to(device)\nloaded.load_state_dict(torch.load('mnist_cnn_model.pth', map_location=device))\nloaded.eval()\nprint('Model loaded back!')", "outputs": [], "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": "## \u2705 Conclusion & Next Steps\n**You learned:** data prep, CNN basics, training, evaluation, confusion matrix, and feature visualization.  \n**Next:** Try deeper CNNs (VGG/ResNet), switch to CIFAR-10, and play with augmentation/regularization.\n"}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.x"}}, "nbformat": 4, "nbformat_minor": 5}